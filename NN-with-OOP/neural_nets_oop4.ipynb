{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-nets-OOP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivrqqtph4J_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "import math\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import cm\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgHvT6-s4Sv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "N_SAMPLES = 1000\n",
        "X_data, y_data_t = make_moons(n_samples = N_SAMPLES, noise=0.2, random_state=100)\n",
        "y_data = y_data_t.reshape(N_SAMPLES,1)\n",
        "m = int(X_data.shape[0])\n",
        "m_tr = int(math.ceil((90/100)*m))\n",
        "m_cv = int(math.ceil((5/100)*m))\n",
        "m_te = m - (m_tr + m_cv)\n",
        "X_tr = np.zeros((m_tr,X_data.shape[1]))\n",
        "y_tr_t = np.zeros((m_tr,1))\n",
        "X_cv = np.zeros((m_cv,X_data.shape[1]))\n",
        "y_cv_t = np.zeros((m_cv,1))\n",
        "X_te = np.zeros((m_te,X_data.shape[1]))\n",
        "y_te_t = np.zeros((m_te,1))\n",
        "perm = np.random.permutation(m)\n",
        "p = perm.reshape(m,1)\n",
        "for i in range(0,m_tr):\n",
        "  X_tr[i] = X_data[p[i]]\n",
        "  y_tr_t[i] = y_data[p[i]]\n",
        "for i in range(0,m_cv):\n",
        "  X_cv[i] = X_data[p[i+m_tr]]\n",
        "  y_cv_t[i] = y_data[p[i+m_tr]]\n",
        "for i in range(0,m_te):\n",
        "  X_te[i] = X_data[p[i+m_tr+m_cv]]\n",
        "  y_te_t[i] = y_data[p[i+m_tr+m_cv]]\n",
        "y_tr = y_tr_t.T\n",
        "y_cv = y_cv_t.T\n",
        "y_te = y_te_t.T\n"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8jlSLyI4Vkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8d2f1cc5-457f-4371-88df-15a9182e4a75"
      },
      "source": [
        "\n",
        "df = DataFrame(dict(x=X_data[:,0], y=X_data[:,1], label=y_data_t))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "plt.show()\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bsskLfqjSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059752f5-cb5a-438c-d21e-1bf4f503740f"
      },
      "source": [
        "\"\"\"\n",
        "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = mnist.load_data()\n",
        "\n",
        "# Preparing the data\n",
        "Y_tr_resh = Y_train_orig.reshape(60000, 1)\n",
        "Y_te_resh = Y_test_orig.reshape(10000, 1)\n",
        "Y_tr_T = to_categorical(Y_tr_resh, num_classes=10)\n",
        "Y_te_T = to_categorical(Y_te_resh, num_classes=10)\n",
        "y_tr = Y_tr_T.T\n",
        "y_te = Y_te_T.T\n",
        "\n",
        "\n",
        "# Flattening of inputs\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
        "\n",
        "# Preprocessing of Inputs\n",
        "X_tr = X_train_flatten.T / 255.\n",
        "X_te = X_test_flatten.T / 255.\n",
        "num_classes = y_tr.shape[0]\n",
        "m_tr = X_tr.shape[0]\n",
        "m_te = X_te.shape[0]\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = mnist.load_data()\\n\\n# Preparing the data\\nY_tr_resh = Y_train_orig.reshape(60000, 1)\\nY_te_resh = Y_test_orig.reshape(10000, 1)\\nY_tr_T = to_categorical(Y_tr_resh, num_classes=10)\\nY_te_T = to_categorical(Y_te_resh, num_classes=10)\\ny_tr = Y_tr_T.T\\ny_te = Y_te_T.T\\n\\n\\n# Flattening of inputs\\nX_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\\nX_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\\n\\n# Preprocessing of Inputs\\nX_tr = X_train_flatten.T / 255.\\nX_te = X_test_flatten.T / 255.\\nnum_classes = y_tr.shape[0]\\nm_tr = X_tr.shape[0]\\nm_te = X_te.shape[0]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwdt1Y3L4fNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Activations:\n",
        "  \"\"\"\n",
        "      Contains the activation functions and their gradients along with the variables \n",
        "      necessary for initializing the weights of the neural network.\n",
        "      SubClasses:\n",
        "        ActivationsForward\n",
        "        ActivationsBackward\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "    \n",
        "  @staticmethod\n",
        "  def tanh(x):\n",
        "    return np.tanh(x)\n",
        "    \n",
        "  @staticmethod\n",
        "  def sigmoid(x):\n",
        "    calc = 1 / (1 + np.exp(-x))\n",
        "    return calc\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    soft = np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "    return soft\n",
        "\n",
        "  @staticmethod\n",
        "  def relu_backward(x):\n",
        "    x[x<=0] = 0\n",
        "    x[x>0] = 1\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_backward(x):\n",
        "    return (1 - np.square(Activations.tanh(x)))\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_backward(x):\n",
        "    sig = Activations.sigmoid(x)\n",
        "    return sig*(1-sig)\n",
        "  \n",
        "  @staticmethod\n",
        "  def softmax_backward(x):\n",
        "    calc = Activations.softmax(x)\n",
        "    return calc*(1-calc)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2mRCFtX4xC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Helpers:\n",
        "  \"\"\"\n",
        "      Contains the helper functions for calculating Cost Function, predicting and\n",
        "      accuracy of the network\n",
        "      Methods:\n",
        "        CostFunction\n",
        "        Predictions\n",
        "        Accuracy\n",
        "  \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def predict(A,threshold=0.5):\n",
        "    predictions = np.zeros((A.shape))\n",
        "    for g in range(0,A.shape[1]):\n",
        "      if A[:,g] >= threshold:\n",
        "        predictions[:,g] = 1\n",
        "    return predictions\n",
        "  \n",
        "  @staticmethod\n",
        "  def predict_multi(A):\n",
        "    predictions_multi = np.zeros(A.shape)\n",
        "    for v in range(0,A.shape[1]):\n",
        "      temp = max(A[:,v])\n",
        "      for w in range(0,A.shape[0]):\n",
        "        if A[w,v] == temp:\n",
        "          predictions_multi[w,v] = 1\n",
        "        else:\n",
        "          predictions_multi[w,v] = 0\n",
        "    return predictions_multi\n",
        "\n",
        "  @staticmethod\n",
        "  def evaluate(y, preds,A=None):\n",
        "    accuracy = float(np.mean(preds==y,axis=1)*100)\n",
        "    return accuracy\n",
        "\n",
        "  @staticmethod\n",
        "  def evaluate_multi(y,preds,A):\n",
        "    predictions_multi = Helpers.predict_multi(A)\n",
        "    ones_array = np.ones(preds.shape)\n",
        "    temp1 = preds==ones_array\n",
        "    ind = []\n",
        "    for gee in range(0,temp1.shape[1]):\n",
        "      for jee in range(0,temp1.shape[0]):\n",
        "        if temp1[jee,gee] == True:\n",
        "          ind.append(jee)\n",
        "    ind_arr = np.array(ind)\n",
        "    y_list = []\n",
        "    for gee in range(0,y.shape[1]):\n",
        "      for jee in range(0,y.shape[0]):\n",
        "        if y[jee,gee] == 1:\n",
        "          y_list.append(jee)\n",
        "    y_arr = np.array(y_list)\n",
        "    accuracy = float(np.mean(ind_arr == y_arr.T))*100\n",
        "    return accuracy\n",
        "  \n",
        "  @staticmethod\n",
        "  def prec_rec(A,y):\n",
        "    epsilon = 1e-5\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for i in range(0,y.shape[1]):\n",
        "      if ((A[0,i]==1)and(y[0,i]==1)):\n",
        "        tp = tp+1\n",
        "      if ((A[0,i]==1)and(y[0,i]==0)):\n",
        "        fp = fp+1\n",
        "      if (A[0,i]==0)and(y[0,i]==1):\n",
        "        fn = fn+1\n",
        "    prec = tp/(tp+fp+epsilon)\n",
        "    rec = tp/(tp+fn+epsilon)\n",
        "    f1 = (2*prec*rec)/(prec+rec+epsilon)\n",
        "    return prec,rec,f1\n",
        "\n",
        "  @staticmethod\n",
        "  def prec_rec_multi(A,y):\n",
        "    epsilon = 1e-5\n",
        "    tp_multi = {}\n",
        "    fp_multi = {}\n",
        "    fn_multi = {}\n",
        "    prec_multi = {}\n",
        "    rec_multi = {}\n",
        "    f1_multi = {}\n",
        "    for r in range(0,num_classes):\n",
        "      tp_multi[\"class\" + str(r)] = 0\n",
        "      fp_multi[\"class\" + str(r)] = 0\n",
        "      fn_multi[\"class\" + str(r)] = 0\n",
        "    for c in range(0,y.shape[1]):\n",
        "      for g in range(0,y.shape[0]):\n",
        "        if ((A[g,c]==1) and (y[g,c]==1)):\n",
        "          tp_multi[\"class\" + str(g)] = tp_multi[\"class\" + str(g)] + 1\n",
        "        if ((A[g,c]==1) and (y[g,c]==0)):\n",
        "          fp_multi[\"class\" + str(g)] = fp_multi[\"class\" + str(g)] + 1\n",
        "        if ((A[g,c]==0) and (y[g,c]==1)):\n",
        "          fn_multi[\"class\" + str(g)] = fn_multi[\"class\" + str(g)] + 1\n",
        "    for n in range(0,num_classes):\n",
        "      prec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fp_multi[\"class\" + str(n)] + epsilon)\n",
        "      rec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fn_multi[\"class\" + str(n)] + epsilon)\n",
        "      f1_multi[\"class\" + str(n)] = (2*prec_multi[\"class\" + str(n)]*rec_multi[\"class\" + str(n)])/(prec_multi[\"class\" + str(n)] + rec_multi[\"class\" + str(n)] + epsilon)\n",
        "    return prec_multi,rec_multi,f1_multi\n",
        "\n",
        "  @staticmethod\n",
        "  def grad_L1_reg(layers_arr):\n",
        "    for layer in layers_arr:\n",
        "      layer.grad_L1 = np.zeros(layer.weights.shape)\n",
        "      for p in range(0,layer.weights.shape[0]):\n",
        "        for n in range(0,layer.weights.shape[1]):\n",
        "          if layer.weights[p,n] > 0:\n",
        "            layer.grad_L1[p,n] = 1\n",
        "          else:\n",
        "            layer.grad_L1[p,n] = -1\n",
        "\n",
        "  @staticmethod\n",
        "  def create_mini_batches(X,y,mb_size):\n",
        "    m_ex = y.shape[1]\n",
        "    mini_batch = {}\n",
        "    num = m_ex//mb_size\n",
        "    if (m_ex%mb_size != 0):\n",
        "      f = 0\n",
        "      for p in range(0,num):\n",
        "        mini_batch[\"MB_X\" + str(p)] = X[f:(f+mb_size),:]\n",
        "        mini_batch[\"MB_Y\" + str(p)] = y[:,f:(f+mb_size)]\n",
        "        f = f + mb_size\n",
        "      mini_batch[\"MB_X\" + str(num)] = X[f:m_ex,:]\n",
        "      mini_batch[\"MB_Y\" + str(num)] = y[:,f:m_ex]\n",
        "      return mini_batch,num\n",
        "    else:\n",
        "      f = 0\n",
        "      for p in range(0,num-1):\n",
        "        mini_batch[\"MB_X\" + str(p)] = X[f:(f+mb_size),:]\n",
        "        mini_batch[\"MB_Y\" + str(p)] = y[:,f:(f+mb_size)]\n",
        "        f = f + mb_size\n",
        "      mini_batch[\"MB_X\" + str(num-1)] = X[f:m_ex,:]\n",
        "      mini_batch[\"MB_Y\" + str(num-1)] = y[:,f:m_ex]\n",
        "      return mini_batch,num-1"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siFjv8uhy6jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regularization:\n",
        "  @staticmethod\n",
        "  def L1_reg(layers_arr,lamb,m_exam):\n",
        "    temp_sum = 0\n",
        "    for layers in layers_arr:\n",
        "      temp_sum = temp_sum + ((lamb/m_exam)*(np.sum(np.sum(layers.weights))))\n",
        "      layers.grad_reg = ((lamb/m_exam)*(layers.grad_L1))\n",
        "    return temp_sum\n",
        "  \n",
        "  @staticmethod\n",
        "  def L2_reg(layers_arr,lamb,m_exam):\n",
        "    temp_sum = 0\n",
        "    for layers in layers_arr:\n",
        "      temp_sum = temp_sum + ((lamb/(2*m_exam))*(np.sum(np.sum(np.square(layers.weights)))))\n",
        "      layers.grad_reg = ((lamb/m_exam)*(layers.weights))\n",
        "    return temp_sum"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObfSBrXWNQHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CostFunction:\n",
        "  @staticmethod\n",
        "  def binary_cross_entropy(y,A,layers_arr,lamb,reg=None):\n",
        "    if reg is not None:\n",
        "      if reg is \"L1\":\n",
        "        Helpers.grad_L1_reg(layers_arr)\n",
        "        temp_sum = Regularization.L1_reg(layers_arr,lamb,y.shape[1])\n",
        "      if reg is \"L2\":\n",
        "        temp_sum = Regularization.L2_reg(layers_arr,lamb,y.shape[1])\n",
        "      cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)) + ((1-y)*(np.log(1-A)))))) + temp_sum\n",
        "      grad = (-1/y.shape[1])*((y/A)-((1-y)/(1-A)))\n",
        "    else:\n",
        "      cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)) + ((1-y)*(np.log(1-A))))))\n",
        "      grad = (-1/y.shape[1])*((y/A)-((1-y)/(1-A)))\n",
        "      for layers in layers_arr:\n",
        "        layers.grad_reg = 0\n",
        "    return cost,grad\n",
        "\n",
        "  @staticmethod\n",
        "  def cross_entropy(y,A,layers_arr,lamb,reg=None):\n",
        "    if reg is not None:\n",
        "      if reg is \"L1\":\n",
        "        Helpers.grad_L1_reg(layers_arr)\n",
        "        temp_sum = Regularization.L1_reg(layers_arr,lamb,y.shape[1])\n",
        "      if reg is \"L2\":\n",
        "        temp_sum = Regularization.L2_reg(layers_arr,lamb,y.shape[1])\n",
        "      cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)))))\n",
        "      grad = (-1/y.shape[1])*((y/A))\n",
        "    else:\n",
        "      cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)))))\n",
        "      grad = (-1/y.shape[1])*((y/A))\n",
        "      for layers in layers_arr:\n",
        "        layers.grad_reg = 0\n",
        "    return cost,grad"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7kaqWb5_-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense:\n",
        "  \"\"\"\n",
        "      This layer is used for implemetation of Fully Connected Neural Networks\n",
        "      Methods:\n",
        "        Parameters Initialization\n",
        "        Forward Propagation\n",
        "        Backward Propagation\n",
        "  \"\"\"\n",
        "  def __init__(self,num_inputs,num_outputs,activation_fn,dropout=1.0,weights=None,bias=None,dZ=None,dW=None,db=None,dA=None,grad_L1=None,grad_reg=None):\n",
        "    self.num_inputs = num_inputs\n",
        "    self.num_outputs = num_outputs\n",
        "    self.activation_fn = activation_fn\n",
        "    self.dropout = dropout\n",
        "    self.dZ,self.dW,self.db,self.dA = dZ,dW,db,dA\n",
        "    self.grad_L1 = grad_L1\n",
        "    self.grad_reg = grad_reg\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "    self.activ_dict = {\"relu\":[Activations.relu,Activations.relu_backward,2],\n",
        "                       \"tanh\":[Activations.tanh,Activations.tanh_backward,1],\n",
        "                       \"sigmoid\":[Activations.sigmoid,Activations.sigmoid_backward,1],\n",
        "                       \"softmax\":[Activations.softmax,Activations.softmax_backward,1]}\n",
        "\n",
        "  def initialize_params(self):\n",
        "    self.weights = np.random.randn(self.num_outputs,self.num_inputs)*(np.sqrt(self.activ_dict[self.activation_fn][2]/self.num_inputs))\n",
        "    self.bias = np.random.randn(self.num_outputs, 1)*0.01\n",
        "    return self.weights,self.bias\n",
        "\n",
        "  def get_params(self):\n",
        "    return self.weights, self.bias\n",
        "    \n",
        "  def forw_prop(self,A_prev,train=True):\n",
        "    if train is False:\n",
        "      self.dropout = 1\n",
        "    self.outputs = np.dot(self.weights,A_prev) + self.bias\n",
        "    self.activations_temp = self.activ_dict[self.activation_fn][0](self.outputs)\n",
        "    self.activations = self.activations_temp*((np.random.rand(self.outputs.shape[0],self.outputs.shape[1]) < self.dropout)/self.dropout)\n",
        "    return self.outputs,self.activations\n",
        "\n",
        "  def back_prop(self,dA_prev,A_prev):\n",
        "    self.dZ = dA_prev*self.activ_dict[self.activation_fn][1](self.outputs)\n",
        "    self.dW = (np.dot(self.dZ,A_prev.T)) + self.grad_reg\n",
        "    self.db = np.sum(self.dZ,axis=1,keepdims = True)\n",
        "    self.dA = np.dot(self.weights.T,self.dZ)\n",
        "    return self.dZ,self.dW,self.db,self.dA"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PI_-trs6vsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizers:\n",
        "  \"\"\"\n",
        "      Contains the optimizers for the Neural Networks and for updating of parameters\n",
        "      SubClasses:\n",
        "        GradientDescent\n",
        "        Adam\n",
        "        Momentum\n",
        "        StochasticGradientDescent\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def gradient_descent(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    for layers in layers_arr:\n",
        "      layers.weights -= (alpha*layers.dW)\n",
        "      layers.bias -= (alpha*layers.db)\n",
        "\n",
        "  @staticmethod\n",
        "  def gd_mom(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta1 = 0.9\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      V_dict[\"Vdw\" + str(h)] = (beta1*V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*layers_arr[h-1].dW)\n",
        "      V_dict[\"Vdb\" + str(h)] = (beta1*V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*layers_arr[h-1].db)\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= (alpha*V_dict[\"Vdw\" + str(g)])\n",
        "      layers_arr[g-1].bias -= (alpha*V_dict[\"Vdb\" + str(g)])\n",
        "  \n",
        "  @staticmethod\n",
        "  def rms_prop(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      S_dict[\"Sdw\" + str(h)] = (beta2*S_dict[\"Sdw\" + str(h)]) + ((1-beta2)*np.square(layers_arr[h-1].dW))\n",
        "      S_dict[\"Sdb\" + str(h)] = (beta2*S_dict[\"Sdb\" + str(h)]) + ((1-beta2)*np.square(layers_arr[h-1].db))\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= ((alpha*layers_arr[g-1].dW)/(np.sqrt(S_dict[\"Sdw\" + str(g)]) + epsilon))\n",
        "      layers_arr[g-1].bias -= ((alpha*layers_arr[g-1].db)/(np.sqrt(S_dict[\"Sdb\" + str(g)]) + epsilon))\n",
        "\n",
        "  @staticmethod\n",
        "  def adam(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "    S_dict_corr = {}\n",
        "    V_dict_corr = {}\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      V_dict[\"Vdw\" + str(h)] = (beta1*V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*layers_arr[h-1].dW)\n",
        "      V_dict[\"Vdb\" + str(h)] = (beta1*V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*layers_arr[h-1].db)\n",
        "    for u in range(1,len(layers_arr)+1):\n",
        "      S_dict[\"Sdw\" + str(u)] = (beta2*S_dict[\"Sdw\" + str(u)]) + ((1-beta2)*np.square(layers_arr[u-1].dW))\n",
        "      S_dict[\"Sdb\" + str(u)] = (beta2*S_dict[\"Sdb\" + str(u)]) + ((1-beta2)*np.square(layers_arr[u-1].db))\n",
        "    for n in range(1,len(layers_arr)+1):\n",
        "      S_dict_corr[\"Sdw\" + str(n)] = S_dict[\"Sdw\" + str(n)]/(1 - np.power(beta2,t))\n",
        "      S_dict_corr[\"Sdb\" + str(n)] = S_dict[\"Sdb\" + str(n)]/(1 - np.power(beta2,t))\n",
        "      V_dict_corr[\"Vdw\" + str(n)] = V_dict[\"Vdw\" + str(n)]/(1 - np.power(beta1,t))\n",
        "      V_dict_corr[\"Vdb\" + str(n)] = V_dict[\"Vdb\" + str(n)]/(1 - np.power(beta1,t))\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= ((alpha*V_dict_corr[\"Vdw\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdw\" + str(g)]) + epsilon))\n",
        "      layers_arr[g-1].bias -= ((alpha*V_dict_corr[\"Vdb\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdb\" + str(g)]) + epsilon))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzuSI-Kp7JvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  \"\"\"\n",
        "      Binds all the other classes together and contains methods for adding layers,\n",
        "      training the network and testing the network\n",
        "      Methods:\n",
        "        Add\n",
        "        Fit\n",
        "        Test\n",
        "  \"\"\" \n",
        "  def __init__(self,X_tr,y_tr,X_te,y_te,X_cv,y_cv):\n",
        "    self.X_tr, self.y_tr, self.m_tr = X_tr, y_tr, X_tr.shape[0] \n",
        "    self.X_te, self.y_te, self.m_te = X_te, y_te, X_te.shape[0]\n",
        "    self.X_cv, self.y_cv, self.m_cv = X_cv, y_cv, X_cv.shape[0]\n",
        "    self.layer_names = []\n",
        "    self.activations_cache = None\n",
        "    self.params = None\n",
        "\n",
        "  def add(self,layer_name,num_inputs,num_outputs,act_fn,dropout=1):\n",
        "    layer_name = Dense(num_inputs,num_outputs,act_fn,dropout)\n",
        "    Dense.initialize_params(layer_name)\n",
        "    self.layer_names.append(layer_name)\n",
        "  \n",
        "  def reset(self):\n",
        "    self.layer_names = []\n",
        "    return self.layer_names\n",
        "\n",
        "  def params_dict(self,print_params):\n",
        "    self.params = {}\n",
        "    hee = 1\n",
        "    for layer in self.layer_names:\n",
        "      self.params[\"W\" + str(hee)],self.params[\"b\" + str(hee)] = Dense.get_params(layer)\n",
        "      hee += 1\n",
        "    if print_params is True:\n",
        "      print(self.params)\n",
        "      return self.params\n",
        "    else:\n",
        "      return self.params\n",
        "\n",
        "  def forward_prop(self,X,train_model=True):\n",
        "    self.activations_cache = {}\n",
        "    self.activations_cache = {\"A0\":X.T}\n",
        "    temp_A = X.T\n",
        "    p = 1\n",
        "    for layer in self.layer_names:\n",
        "      _,temp_A = Dense.forw_prop(layer,temp_A,train_model)\n",
        "      self.activations_cache[\"A\" + str(p)] = temp_A\n",
        "      p += 1\n",
        "    return self.activations_cache\n",
        "\n",
        "  def backward_prop(self,y,prob_type,activations_cache,lamb,reg):\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    _,temp_dA = prob_type_dict[prob_type][0](y,activations_cache[\"A\" + str(len(self.layer_names))],self.layer_names,lamb,reg)\n",
        "    l = 1\n",
        "    for layer in reversed(self.layer_names):\n",
        "      _,layer.dW,layer.db,temp_dA = Dense.back_prop(layer,temp_dA,self.activations_cache[\"A\" + str(len(self.layer_names)-l)])\n",
        "      l += 1\n",
        "  \n",
        "  def fit(self,X,y,alpha,num_iter,optim,prob_type,mb,reg=None,lamb=None,print_cost=True,callback=None):\n",
        "    params = self.params_dict(print_params=False)\n",
        "    V_dict = {}\n",
        "    S_dict = {}\n",
        "    mini_batches,num = Helpers.create_mini_batches(X,y,mb)\n",
        "\n",
        "    for k in range(1,len(self.layer_names)+1):\n",
        "      V_dict[\"Vdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
        "      V_dict[\"Vdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
        "      S_dict[\"Sdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
        "      S_dict[\"Sdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
        "    optim_dict = {\"BGD\":[Optimizers.gradient_descent,None,None,0],\n",
        "                  \"Momentum\":[Optimizers.gd_mom,V_dict,None,0],\n",
        "                  \"RMSprop\":[Optimizers.rms_prop,None,S_dict,0],\n",
        "                  \"Adam\":[Optimizers.adam,V_dict,S_dict,0]}\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    \n",
        "    for i in range(1,num_iter+1):\n",
        "      params_plot = self.params_dict(print_params=False)\n",
        "      for vee in range(0,num+1):\n",
        "        activations_dict = self.forward_prop(mini_batches[\"MB_X\" + str(vee)])\n",
        "        self.backward_prop(mini_batches[\"MB_Y\" + str(vee)],prob_type,activations_dict,lamb,reg)\n",
        "        optim_dict[optim][0](alpha,self.layer_names,optim_dict[optim][1],optim_dict[optim][2],optim_dict[optim][3]+i)\n",
        "      act_tr = self.forward_prop(X)\n",
        "      cost,_ = prob_type_dict[prob_type][0](y,act_tr[\"A\" + str(len(self.layer_names))],self.layer_names,lamb,reg)\n",
        "      preds = prob_type_dict[prob_type][2](act_tr[\"A\" + str(len(self.layer_names))])\n",
        "      accu_tr = prob_type_dict[prob_type][3](y,preds,act_tr[\"A\" + str(len(self.layer_names))])\n",
        "      if ((i%50==0) and print_cost==True):\n",
        "        print(\"Cost after iteration \" + str(i) + \" is: \" + str(np.round(cost,6)) + \"-----\" + \"Training accuracy: \" + str(np.round(accu_tr,3)))\n",
        "      if (i % 1 == 0):\n",
        "        if(callback is not None):\n",
        "          callback(i, params_plot)\n",
        "\n",
        "  def test(self,X,y,prob_type,training=False,print_values=True):\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    act_te = self.forward_prop(X,training)\n",
        "    predictions_te = prob_type_dict[prob_type][2](act_te[\"A\" + str(len(self.layer_names))])\n",
        "    accu_te = prob_type_dict[prob_type][3](y,predictions_te,act_te[\"A\" + str(len(self.layer_names))])\n",
        "    prec_te,rec_te,f1_te = prob_type_dict[prob_type][1](predictions_te,y)\n",
        "    if print_values is True:\n",
        "      print(\"TEST RESULTS: \")\n",
        "      print(\"Testing accuracy = \" + str(accu_te))\n",
        "      print(\"Precision: \" + str(prec_te))\n",
        "      print(\"Recall: \" + str(rec_te))\n",
        "      print(\"F1 score: \" + str(f1_te))\n",
        "      print('\\n')\n",
        "      print('\\n')\n",
        "    return accu_te,prec_te,rec_te,f1_te"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5TZ10m7v-fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(X_tr,y_tr,X_te,y_te,X_cv,y_cv)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT0OtJX1_CYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.reset()\n",
        "model.add(\"dense1\",X_tr.shape[1],500,\"relu\")\n",
        "model.add(\"dense2\",500,250,\"relu\")\n",
        "model.add(\"dense3\",250,150,\"relu\",0.6)\n",
        "model.add(\"dense4\",150,100,\"relu\",0.7)\n",
        "model.add(\"dense5\",100,60,\"relu\",0.9)\n",
        "model.add(\"dense6\",60,30,\"tanh\",0.9)\n",
        "model.add(\"dense7\",30,1,\"sigmoid\")"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG1JGDB4_asI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_tr,y_tr,0.0005,250,\"Adam\",\"Binary\",mb=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLLHKYp2i3yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.test(X_te,y_te,\"Binary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkqT5Tk3tNX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "GRID_X_START = -1.5\n",
        "GRID_X_END = 2.5\n",
        "GRID_Y_START = -1.0\n",
        "GRID_Y_END = 2\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/nn_visuals/oop_adam\"\n",
        "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
        "grid_2d = grid.reshape(2,-1)\n",
        "XX, YY = grid\n",
        "def make_plot(X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False):\n",
        "    if (dark):\n",
        "        plt.style.use('dark_background')\n",
        "    else:\n",
        "        sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16,12))\n",
        "    axes = plt.gca()\n",
        "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
        "    plt.title(plot_name, fontsize=30)\n",
        "    plt.subplots_adjust(left=0.20)\n",
        "    plt.subplots_adjust(right=0.80)\n",
        "    if(XX is not None and YY is not None and preds is not None):\n",
        "        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha = 1, cmap=cm.Spectral)\n",
        "        plt.contour(XX, YY, preds.reshape(XX.shape), levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
        "    if(file_name):\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "import os\n",
        "def callback_numpy_plot(index, init_params):\n",
        "    plot_title = \"Iteration {:05}\".format(index)\n",
        "    file_name = \"numpy_model_{:05}.png\".format(index//1)\n",
        "    file_path = os.path.join(OUTPUT_DIR, file_name)\n",
        "    act = model.forward_prop(np.transpose(grid_2d),train_model=False)\n",
        "    prediction_probs = act[\"A6\"]\n",
        "    prediction_probs = prediction_probs.reshape(prediction_probs.shape[1], 1)\n",
        "    make_plot(X_cv, y_cv, plot_title, file_name=file_path, XX=XX, YY=YY, preds=prediction_probs, dark=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBa5oLGS0FPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.reset()\n",
        "model.add(\"dense1\",X_tr.shape[1],250,\"relu\")\n",
        "model.add(\"dense2\",250,150,\"relu\")\n",
        "model.add(\"dense3\",150,100,\"relu\")\n",
        "model.add(\"dense4\",100,60,\"relu\")\n",
        "model.add(\"dense5\",60,30,\"tanh\")\n",
        "model.add(\"dense6\",30,1,\"sigmoid\")\n",
        "model.fit(X_tr,y_tr,0.0005,50,\"Adam\",\"Binary\",mb=32,print_cost=False,callback=callback_numpy_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSr56u3m2VfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = model.forward_prop(np.transpose(grid_2d),train_model=True)\n",
        "prediction_probs_np = act[\"A6\"]\n",
        "prediction_probs_np = prediction_probs_np.reshape(prediction_probs_np.shape[1], 1)\n",
        "make_plot(X_cv, y_cv, \"Final Iteration\", file_name=None, XX=XX, YY=YY, preds=prediction_probs_np, dark=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG8sPwML4PDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}