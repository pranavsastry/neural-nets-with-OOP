{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-nets-OOP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivrqqtph4J_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f647362-7c60-49cf-c113-cd213d46e28f"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "import math\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import cm\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgHvT6-s4Sv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8f9b1fd0-0c4a-4c14-d786-9527e86581f1"
      },
      "source": [
        "\"\"\"\n",
        "N_SAMPLES = 1000\n",
        "X_data, y_data_t = make_moons(n_samples = N_SAMPLES, noise=0.2, random_state=50)\n",
        "y_data = y_data_t.reshape(N_SAMPLES,1)\n",
        "m = int(X_data.shape[0])\n",
        "m_tr = int(math.ceil((90/100)*m))\n",
        "m_cv = int(math.ceil((5/100)*m))\n",
        "m_te = m - (m_tr + m_cv)\n",
        "X_tr = np.zeros((m_tr,X_data.shape[1]))\n",
        "y_tr_t = np.zeros((m_tr,1))\n",
        "X_cv = np.zeros((m_cv,X_data.shape[1]))\n",
        "y_cv_t = np.zeros((m_cv,1))\n",
        "X_te = np.zeros((m_te,X_data.shape[1]))\n",
        "y_te_t = np.zeros((m_te,1))\n",
        "perm = np.random.permutation(m)\n",
        "p = perm.reshape(m,1)\n",
        "for i in range(0,m_tr):\n",
        "  X_tr[i] = X_data[p[i]]\n",
        "  y_tr_t[i] = y_data[p[i]]\n",
        "for i in range(0,m_cv):\n",
        "  X_cv[i] = X_data[p[i+m_tr]]\n",
        "  y_cv_t[i] = y_data[p[i+m_tr]]\n",
        "for i in range(0,m_te):\n",
        "  X_te[i] = X_data[p[i+m_tr+m_cv]]\n",
        "  y_te_t[i] = y_data[p[i+m_tr+m_cv]]\n",
        "y_tr = y_tr_t.T\n",
        "y_cv = y_cv_t.T\n",
        "y_te = y_te_t.T\n",
        "\"\"\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nN_SAMPLES = 1000\\nX_data, y_data_t = make_moons(n_samples = N_SAMPLES, noise=0.2, random_state=50)\\ny_data = y_data_t.reshape(N_SAMPLES,1)\\nm = int(X_data.shape[0])\\nm_tr = int(math.ceil((90/100)*m))\\nm_cv = int(math.ceil((5/100)*m))\\nm_te = m - (m_tr + m_cv)\\nX_tr = np.zeros((m_tr,X_data.shape[1]))\\ny_tr_t = np.zeros((m_tr,1))\\nX_cv = np.zeros((m_cv,X_data.shape[1]))\\ny_cv_t = np.zeros((m_cv,1))\\nX_te = np.zeros((m_te,X_data.shape[1]))\\ny_te_t = np.zeros((m_te,1))\\nperm = np.random.permutation(m)\\np = perm.reshape(m,1)\\nfor i in range(0,m_tr):\\n  X_tr[i] = X_data[p[i]]\\n  y_tr_t[i] = y_data[p[i]]\\nfor i in range(0,m_cv):\\n  X_cv[i] = X_data[p[i+m_tr]]\\n  y_cv_t[i] = y_data[p[i+m_tr]]\\nfor i in range(0,m_te):\\n  X_te[i] = X_data[p[i+m_tr+m_cv]]\\n  y_te_t[i] = y_data[p[i+m_tr+m_cv]]\\ny_tr = y_tr_t.T\\ny_cv = y_cv_t.T\\ny_te = y_te_t.T\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8jlSLyI4Vkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "be86b223-29c3-4eec-9856-7ca4ff48c6c5"
      },
      "source": [
        "\"\"\"\n",
        "df = DataFrame(dict(x=X_data[:,0], y=X_data[:,1], label=y_data_t))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = plt.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndf = DataFrame(dict(x=X_data[:,0], y=X_data[:,1], label=y_data_t))\\ncolors = {0:'red', 1:'blue'}\\nfig, ax = plt.subplots()\\ngrouped = df.groupby('label')\\nfor key, group in grouped:\\n    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\\nplt.show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bsskLfqjSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = mnist.load_data()\n",
        "\n",
        "# Preparing the data\n",
        "Y_tr_resh = Y_train_orig.reshape(60000, 1)\n",
        "Y_te_resh = Y_test_orig.reshape(10000, 1)\n",
        "Y_tr_T = to_categorical(Y_tr_resh, num_classes=10)\n",
        "Y_te_T = to_categorical(Y_te_resh, num_classes=10)\n",
        "y_tr = Y_tr_T.T\n",
        "y_te = Y_te_T.T\n",
        "\n",
        "\n",
        "# Flattening of inputs\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
        "\n",
        "# Preprocessing of Inputs\n",
        "X_tr = X_train_flatten.T / 255.\n",
        "X_te = X_test_flatten.T / 255.\n",
        "num_classes = y_tr.shape[0]\n",
        "m_tr = X_tr.shape[0]\n",
        "m_te = X_te.shape[0]\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwdt1Y3L4fNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Activations:\n",
        "  \"\"\"\n",
        "      Contains the activation functions and their gradients along with the variables \n",
        "      necessary for initializing the weights of the neural network.\n",
        "      SubClasses:\n",
        "        ActivationsForward\n",
        "        ActivationsBackward\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "    \n",
        "  @staticmethod\n",
        "  def tanh(x):\n",
        "    return np.tanh(x)\n",
        "    \n",
        "  @staticmethod\n",
        "  def sigmoid(x):\n",
        "    calc = 1 / (1 + np.exp(-x))\n",
        "    return calc\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    soft = np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "    return soft\n",
        "\n",
        "  @staticmethod\n",
        "  def relu_backward(x):\n",
        "    x[x<=0] = 0\n",
        "    x[x>0] = 1\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_backward(x):\n",
        "    return (1 - np.square(Activations.tanh(x)))\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_backward(x):\n",
        "    sig = Activations.sigmoid(x)\n",
        "    return sig*(1-sig)\n",
        "  \n",
        "  @staticmethod\n",
        "  def softmax_backward(x):\n",
        "    calc = Activations.softmax(x)\n",
        "    return calc*(1-calc)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObfSBrXWNQHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CostFunction:\n",
        "  @staticmethod\n",
        "  def binary_cross_entropy(y, A):\n",
        "    cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)) + ((1-y)*(np.log(1-A))))))\n",
        "    grad = (-1/y.shape[1])*((y/A)-((1-y)/(1-A)))\n",
        "    return cost,grad\n",
        "\n",
        "  @staticmethod\n",
        "  def cross_entropy(y,A):\n",
        "    cost = (-1/y.shape[1])*(np.sum(np.sum((y*np.log(A)))))\n",
        "    grad = (-1/y.shape[1])*((y/A))\n",
        "    return cost,grad"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2mRCFtX4xC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Helpers:\n",
        "  \"\"\"\n",
        "      Contains the helper functions for calculating Cost Function, predicting and\n",
        "      accuracy of the network\n",
        "      Methods:\n",
        "        CostFunction\n",
        "        Predictions\n",
        "        Accuracy\n",
        "  \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def predict(A,threshold=0.5):\n",
        "    predictions = np.zeros((A.shape))\n",
        "    for g in range(0,A.shape[1]):\n",
        "      if A[:,g] >= threshold:\n",
        "        predictions[:,g] = 1\n",
        "    return predictions\n",
        "  \n",
        "  @staticmethod\n",
        "  def predict_multi(A):\n",
        "    predictions_multi = np.zeros(A.shape)\n",
        "    for v in range(0,A.shape[1]):\n",
        "      temp = max(A[:,v])\n",
        "      for w in range(0,A.shape[0]):\n",
        "        if A[w,v] == temp:\n",
        "          predictions_multi[w,v] = 1\n",
        "        else:\n",
        "          predictions_multi[w,v] = 0\n",
        "    return predictions_multi\n",
        "\n",
        "  @staticmethod\n",
        "  def evaluate(y, preds,A=None):\n",
        "    accuracy = float(np.mean(preds==y,axis=1)*100)\n",
        "    return accuracy\n",
        "\n",
        "  @staticmethod\n",
        "  def evaluate_multi(y,preds,A):\n",
        "    predictions_multi = Helpers.predict_multi(A)\n",
        "    ones_array = np.ones(preds.shape)\n",
        "    temp1 = preds==ones_array\n",
        "    ind = []\n",
        "    for gee in range(0,temp1.shape[1]):\n",
        "      for jee in range(0,temp1.shape[0]):\n",
        "        if temp1[jee,gee] == True:\n",
        "          ind.append(jee)\n",
        "    ind_arr = np.array(ind)\n",
        "    y_list = []\n",
        "    for gee in range(0,y.shape[1]):\n",
        "      for jee in range(0,y.shape[0]):\n",
        "        if y[jee,gee] == 1:\n",
        "          y_list.append(jee)\n",
        "    y_arr = np.array(y_list)\n",
        "    accuracy = float(np.mean(ind_arr == y_arr.T))*100\n",
        "    return accuracy\n",
        "  \n",
        "  @staticmethod\n",
        "  def prec_rec(A,y):\n",
        "    epsilon = 1e-5\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for i in range(0,y.shape[1]):\n",
        "      if ((A[0,i]==1)and(y[0,i]==1)):\n",
        "        tp = tp+1\n",
        "      if ((A[0,i]==1)and(y[0,i]==0)):\n",
        "        fp = fp+1\n",
        "      if (A[0,i]==0)and(y[0,i]==1):\n",
        "        fn = fn+1\n",
        "    prec = tp/(tp+fp+epsilon)\n",
        "    rec = tp/(tp+fn+epsilon)\n",
        "    f1 = (2*prec*rec)/(prec+rec+epsilon)\n",
        "    return prec,rec,f1\n",
        "\n",
        "  @staticmethod\n",
        "  def prec_rec_multi(A,y):\n",
        "    epsilon = 1e-5\n",
        "    tp_multi = {}\n",
        "    fp_multi = {}\n",
        "    fn_multi = {}\n",
        "    prec_multi = {}\n",
        "    rec_multi = {}\n",
        "    f1_multi = {}\n",
        "    for r in range(0,num_classes):\n",
        "      tp_multi[\"class\" + str(r)] = 0\n",
        "      fp_multi[\"class\" + str(r)] = 0\n",
        "      fn_multi[\"class\" + str(r)] = 0\n",
        "    for c in range(0,y.shape[1]):\n",
        "      for g in range(0,y.shape[0]):\n",
        "        if ((A[g,c]==1) and (y[g,c]==1)):\n",
        "          tp_multi[\"class\" + str(g)] = tp_multi[\"class\" + str(g)] + 1\n",
        "        if ((A[g,c]==1) and (y[g,c]==0)):\n",
        "          fp_multi[\"class\" + str(g)] = fp_multi[\"class\" + str(g)] + 1\n",
        "        if ((A[g,c]==0) and (y[g,c]==1)):\n",
        "          fn_multi[\"class\" + str(g)] = fn_multi[\"class\" + str(g)] + 1\n",
        "    for n in range(0,num_classes):\n",
        "      prec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fp_multi[\"class\" + str(n)] + epsilon)\n",
        "      rec_multi[\"class\" + str(n)] = tp_multi[\"class\" + str(n)] / (tp_multi[\"class\" + str(n)] + fn_multi[\"class\" + str(n)] + epsilon)\n",
        "      f1_multi[\"class\" + str(n)] = (2*prec_multi[\"class\" + str(n)]*rec_multi[\"class\" + str(n)])/(prec_multi[\"class\" + str(n)] + rec_multi[\"class\" + str(n)] + epsilon)\n",
        "    return prec_multi,rec_multi,f1_multi\n",
        "\n",
        "  @staticmethod\n",
        "  def create_mini_batches(X,y,mb_size):\n",
        "    m_ex = y.shape[1]\n",
        "    mini_batch = {}\n",
        "    num = m_ex//mb_size\n",
        "    if (m_ex%mb_size != 0):\n",
        "      f = 0\n",
        "      for p in range(0,num):\n",
        "        mini_batch[\"MB_X\" + str(p)] = X[f:(f+mb_size),:]\n",
        "        mini_batch[\"MB_Y\" + str(p)] = y[:,f:(f+mb_size)]\n",
        "        f = f + mb_size\n",
        "      mini_batch[\"MB_X\" + str(num)] = X[f:m_ex,:]\n",
        "      mini_batch[\"MB_Y\" + str(num)] = y[:,f:m_ex]\n",
        "      return mini_batch,num\n",
        "    else:\n",
        "      f = 0\n",
        "      for p in range(0,num-1):\n",
        "        mini_batch[\"MB_X\" + str(p)] = X[f:(f+mb_size),:]\n",
        "        mini_batch[\"MB_Y\" + str(p)] = y[:,f:(f+mb_size)]\n",
        "        f = f + mb_size\n",
        "      mini_batch[\"MB_X\" + str(num-1)] = X[f:m_ex,:]\n",
        "      mini_batch[\"MB_Y\" + str(num-1)] = y[:,f:m_ex]\n",
        "      return mini_batch,num-1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7kaqWb5_-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense:\n",
        "  \"\"\"\n",
        "      This layer is used for implemetation of Fully Connected Neural Networks\n",
        "      Methods:\n",
        "        Parameters Initialization\n",
        "        Forward Propagation\n",
        "        Backward Propagation\n",
        "  \"\"\"\n",
        "  def __init__(self,num_inputs,num_outputs,activation_fn,weights=None,bias=None,dZ=None,dW=None,db=None,dA=None):\n",
        "    self.num_inputs = num_inputs\n",
        "    self.num_outputs = num_outputs\n",
        "    self.activation_fn = activation_fn\n",
        "    self.dZ,self.dW,self.db,self.dA = dZ,dW,db,dA\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "    self.activ_dict = {\"relu\":[Activations.relu,Activations.relu_backward,2],\n",
        "                       \"tanh\":[Activations.tanh,Activations.tanh_backward,1],\n",
        "                       \"sigmoid\":[Activations.sigmoid,Activations.sigmoid_backward,1],\n",
        "                       \"softmax\":[Activations.softmax,Activations.softmax_backward,1]}\n",
        "\n",
        "  def initialize_params(self):\n",
        "    self.weights = np.random.randn(self.num_outputs,self.num_inputs)*(np.sqrt(self.activ_dict[self.activation_fn][2]/self.num_inputs))\n",
        "    self.bias = np.random.randn(self.num_outputs, 1)*0.01\n",
        "    return self.weights,self.bias\n",
        "\n",
        "  def get_params(self):\n",
        "    return self.weights, self.bias\n",
        "    \n",
        "  def forw_prop(self,A_prev):\n",
        "    self.outputs = np.dot(self.weights,A_prev) + self.bias\n",
        "    self.activations = self.activ_dict[self.activation_fn][0](self.outputs)\n",
        "    return self.outputs,self.activations\n",
        "\n",
        "  def back_prop(self,dA_prev,A_prev):\n",
        "    self.dZ = dA_prev*self.activ_dict[self.activation_fn][1](self.outputs)\n",
        "    self.dW = np.dot(self.dZ,A_prev.T)\n",
        "    self.db = np.sum(self.dZ,axis=1,keepdims = True)\n",
        "    self.dA = np.dot(self.weights.T,self.dZ)\n",
        "    return self.dZ,self.dW,self.db,self.dA"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PI_-trs6vsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizers:\n",
        "  \"\"\"\n",
        "      Contains the optimizers for the Neural Networks and for updating of parameters\n",
        "      SubClasses:\n",
        "        GradientDescent\n",
        "        Adam\n",
        "        Momentum\n",
        "        StochasticGradientDescent\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def gradient_descent(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    for layers in layers_arr:\n",
        "      layers.weights -= (alpha*layers.dW)\n",
        "      layers.bias -= (alpha*layers.db)\n",
        "\n",
        "  @staticmethod\n",
        "  def gd_mom(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta1 = 0.9\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      V_dict[\"Vdw\" + str(h)] = (beta1*V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*layers_arr[h-1].dW)\n",
        "      V_dict[\"Vdb\" + str(h)] = (beta1*V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*layers_arr[h-1].db)\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= (alpha*V_dict[\"Vdw\" + str(g)])\n",
        "      layers_arr[g-1].bias -= (alpha*V_dict[\"Vdb\" + str(g)])\n",
        "  \n",
        "  @staticmethod\n",
        "  def rms_prop(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      S_dict[\"Sdw\" + str(h)] = (beta2*S_dict[\"Sdw\" + str(h)]) + ((1-beta2)*np.square(layers_arr[h-1].dW))\n",
        "      S_dict[\"Sdb\" + str(h)] = (beta2*S_dict[\"Sdb\" + str(h)]) + ((1-beta2)*np.square(layers_arr[h-1].db))\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= ((alpha*layers_arr[g-1].dW)/(np.sqrt(S_dict[\"Sdw\" + str(g)]) + epsilon))\n",
        "      layers_arr[g-1].bias -= ((alpha*layers_arr[g-1].db)/(np.sqrt(S_dict[\"Sdb\" + str(g)]) + epsilon))\n",
        "\n",
        "  @staticmethod\n",
        "  def adam(alpha,layers_arr,V_dict,S_dict,t):\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    epsilon = 1e-8\n",
        "    S_dict_corr = {}\n",
        "    V_dict_corr = {}\n",
        "    for h in range(1,len(layers_arr)+1):\n",
        "      V_dict[\"Vdw\" + str(h)] = (beta1*V_dict[\"Vdw\" + str(h)]) + ((1-beta1)*layers_arr[h-1].dW)\n",
        "      V_dict[\"Vdb\" + str(h)] = (beta1*V_dict[\"Vdb\" + str(h)]) + ((1-beta1)*layers_arr[h-1].db)\n",
        "    for u in range(1,len(layers_arr)+1):\n",
        "      S_dict[\"Sdw\" + str(u)] = (beta2*S_dict[\"Sdw\" + str(u)]) + ((1-beta2)*np.square(layers_arr[u-1].dW))\n",
        "      S_dict[\"Sdb\" + str(u)] = (beta2*S_dict[\"Sdb\" + str(u)]) + ((1-beta2)*np.square(layers_arr[u-1].db))\n",
        "    for n in range(1,len(layers_arr)+1):\n",
        "      S_dict_corr[\"Sdw\" + str(n)] = S_dict[\"Sdw\" + str(n)]/(1 - np.power(beta2,t))\n",
        "      S_dict_corr[\"Sdb\" + str(n)] = S_dict[\"Sdb\" + str(n)]/(1 - np.power(beta2,t))\n",
        "      V_dict_corr[\"Vdw\" + str(n)] = V_dict[\"Vdw\" + str(n)]/(1 - np.power(beta1,t))\n",
        "      V_dict_corr[\"Vdb\" + str(n)] = V_dict[\"Vdb\" + str(n)]/(1 - np.power(beta1,t))\n",
        "    for g in range(1,len(layers_arr)+1):\n",
        "      layers_arr[g-1].weights -= ((alpha*V_dict_corr[\"Vdw\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdw\" + str(g)]) + epsilon))\n",
        "      layers_arr[g-1].bias -= ((alpha*V_dict_corr[\"Vdb\" + str(g)])/(np.sqrt(S_dict_corr[\"Sdb\" + str(g)]) + epsilon))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzuSI-Kp7JvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  \"\"\"\n",
        "      Binds all the other classes together and contains methods for adding layers,\n",
        "      training the network and testing the network\n",
        "      Methods:\n",
        "        Add\n",
        "        Fit\n",
        "        Test\n",
        "  \"\"\" \n",
        "  def __init__(self,X_tr,y_tr,X_te,y_te,X_cv,y_cv):\n",
        "    self.X_tr, self.y_tr, self.m_tr = X_tr, y_tr, X_tr.shape[0] \n",
        "    self.X_te, self.y_te, self.m_te = X_te, y_te, X_te.shape[0]\n",
        "    #self.X_cv, self.y_cv, self.m_cv = X_cv, y_cv, X_cv.shape[0]\n",
        "    self.layer_names = []\n",
        "    self.activations_cache = None\n",
        "    self.params = None\n",
        "\n",
        "  def add(self,layer_name,num_inputs,num_outputs,act_fn):\n",
        "    layer_name = Dense(num_inputs,num_outputs,act_fn)\n",
        "    Dense.initialize_params(layer_name)\n",
        "    self.layer_names.append(layer_name)\n",
        "  \n",
        "  def reset(self):\n",
        "    self.layer_names = []\n",
        "    return self.layer_names\n",
        "\n",
        "  def params_dict(self,print_params):\n",
        "    self.params = {}\n",
        "    hee = 1\n",
        "    for layer in self.layer_names:\n",
        "      self.params[\"W\" + str(hee)],self.params[\"b\" + str(hee)] = Dense.get_params(layer)\n",
        "      hee += 1\n",
        "    if print_params is True:\n",
        "      print(self.params)\n",
        "      return self.params\n",
        "    else:\n",
        "      return self.params\n",
        "\n",
        "  def forward_prop(self,X):\n",
        "    self.activations_cache = {}\n",
        "    self.activations_cache = {\"A0\":X.T}\n",
        "    temp_A = X.T\n",
        "    p = 1\n",
        "    for layer in self.layer_names:\n",
        "      _,temp_A = Dense.forw_prop(layer,temp_A)\n",
        "      self.activations_cache[\"A\" + str(p)] = temp_A\n",
        "      p += 1\n",
        "    return self.activations_cache\n",
        "\n",
        "  def backward_prop(self,y,prob_type,activations_cache):\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    _,temp_dA = prob_type_dict[prob_type][0](y,activations_cache[\"A\" + str(len(self.layer_names))])\n",
        "    l = 1\n",
        "    for layer in reversed(self.layer_names):\n",
        "      _,layer.dW,layer.db,temp_dA = Dense.back_prop(layer,temp_dA,self.activations_cache[\"A\" + str(len(self.layer_names)-l)])\n",
        "      l += 1\n",
        "  \n",
        "  def fit(self,X,y,alpha,num_iter,optim,prob_type,mb,print_cost=True,callback=None):\n",
        "    params = self.params_dict(print_params=False)\n",
        "    V_dict = {}\n",
        "    S_dict = {}\n",
        "    mini_batches,num = Helpers.create_mini_batches(X,y,mb)\n",
        "\n",
        "    for k in range(1,len(self.layer_names)+1):\n",
        "      V_dict[\"Vdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
        "      V_dict[\"Vdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
        "      S_dict[\"Sdw\" + str(k)] = np.zeros(params[\"W\" + str(k)].shape)\n",
        "      S_dict[\"Sdb\" + str(k)] = np.zeros(params[\"b\" + str(k)].shape)\n",
        "    optim_dict = {\"BGD\":[Optimizers.gradient_descent,None,None,0],\n",
        "                  \"Momentum\":[Optimizers.gd_mom,V_dict,None,0],\n",
        "                  \"RMSprop\":[Optimizers.rms_prop,None,S_dict,0],\n",
        "                  \"Adam\":[Optimizers.adam,V_dict,S_dict,0]}\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    \n",
        "    for i in range(1,num_iter+1):\n",
        "      params_plot = self.params_dict(print_params=False)\n",
        "      for vee in range(0,num+1):\n",
        "        activations_dict = self.forward_prop(mini_batches[\"MB_X\" + str(vee)])\n",
        "        self.backward_prop(mini_batches[\"MB_Y\" + str(vee)],prob_type,activations_dict)\n",
        "        optim_dict[optim][0](alpha,self.layer_names,optim_dict[optim][1],optim_dict[optim][2],optim_dict[optim][3]+i)\n",
        "      act_tr = self.forward_prop(X)\n",
        "      cost,_ = prob_type_dict[prob_type][0](y,act_tr[\"A\" + str(len(self.layer_names))])\n",
        "      preds = prob_type_dict[prob_type][2](act_tr[\"A\" + str(len(self.layer_names))])\n",
        "      accu_tr = prob_type_dict[prob_type][3](y,preds,act_tr[\"A\" + str(len(self.layer_names))])\n",
        "      if ((i%1==0) and print_cost==True):\n",
        "        print(\"Cost after iteration \" + str(i) + \" is: \" + str(np.round(cost,6)) + \"-----\" + \"Training accuracy: \" + str(np.round(accu_tr,3)))\n",
        "      if (i % 1 == 0):\n",
        "        if(callback is not None):\n",
        "          callback(i, params_plot)\n",
        "\n",
        "  def test(self,X,y,prob_type,print_values=True):\n",
        "    prob_type_dict = {\"Binary\":[CostFunction.binary_cross_entropy,Helpers.prec_rec,Helpers.predict,Helpers.evaluate],\n",
        "                      \"Multi\":[CostFunction.cross_entropy,Helpers.prec_rec_multi,Helpers.predict_multi,Helpers.evaluate_multi]}\n",
        "    act_te = self.forward_prop(X)\n",
        "    predictions_te = prob_type_dict[prob_type][2](act_te[\"A\" + str(len(self.layer_names))])\n",
        "    accu_te = prob_type_dict[prob_type][3](y,predictions_te,act_te[\"A\" + str(len(self.layer_names))])\n",
        "    prec_te,rec_te,f1_te = prob_type_dict[prob_type][1](predictions_te,y)\n",
        "    if print_values is True:\n",
        "      print(\"TEST RESULTS: \")\n",
        "      print(\"Testing accuracy = \" + str(accu_te))\n",
        "      print(\"Precision: \" + str(prec_te))\n",
        "      print(\"Recall: \" + str(rec_te))\n",
        "      print(\"F1 score: \" + str(f1_te))\n",
        "      print('\\n')\n",
        "      print('\\n')\n",
        "    return accu_te,prec_te,rec_te,f1_te"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5TZ10m7v-fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(X_tr,y_tr,X_te,y_te,None,None)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT0OtJX1_CYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.reset()\n",
        "model.add(\"dense1\",X_tr.shape[1],250,\"relu\")\n",
        "model.add(\"dense2\",250,150,\"relu\")\n",
        "model.add(\"dense3\",150,100,\"relu\")\n",
        "model.add(\"dense4\",100,60,\"relu\")\n",
        "model.add(\"dense5\",60,30,\"tanh\")\n",
        "model.add(\"dense6\",30,10,\"softmax\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG1JGDB4_asI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0a78c6b5-8dbc-4740-a0c3-2bec0e8c5e23"
      },
      "source": [
        "model.fit(X_tr,y_tr,0.0005,15,\"Adam\",\"Multi\",mb=32)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 1 is: 0.322784-----Training accuracy: 93.542\n",
            "Cost after iteration 2 is: 0.235463-----Training accuracy: 95.255\n",
            "Cost after iteration 3 is: 0.201715-----Training accuracy: 95.992\n",
            "Cost after iteration 4 is: 0.17832-----Training accuracy: 96.447\n",
            "Cost after iteration 5 is: 0.169008-----Training accuracy: 96.627\n",
            "Cost after iteration 6 is: 0.156804-----Training accuracy: 96.908\n",
            "Cost after iteration 7 is: 0.143804-----Training accuracy: 97.142\n",
            "Cost after iteration 8 is: 0.125865-----Training accuracy: 97.347\n",
            "Cost after iteration 9 is: 0.115499-----Training accuracy: 97.597\n",
            "Cost after iteration 10 is: 0.103503-----Training accuracy: 97.935\n",
            "Cost after iteration 11 is: 0.095754-----Training accuracy: 98.195\n",
            "Cost after iteration 12 is: 0.082018-----Training accuracy: 98.53\n",
            "Cost after iteration 13 is: 0.07745-----Training accuracy: 98.618\n",
            "Cost after iteration 14 is: 0.091548-----Training accuracy: 98.36\n",
            "Cost after iteration 15 is: 0.079369-----Training accuracy: 98.582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLLHKYp2i3yT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "1dc23131-923e-4a76-db28-8ea2cbfcb741"
      },
      "source": [
        "model.test(X_te,y_te,\"Multi\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST RESULTS: \n",
            "Testing accuracy = 96.50999999999999\n",
            "Precision: {'class0': 0.9847560875532918, 'class1': 0.9955317158576255, 'class2': 0.9852652162547622, 'class3': 0.8948322674992542, 'class4': 0.9782833404520854, 'class5': 0.9622222115308643, 'class6': 0.9859154822761053, 'class7': 0.9743842268533573, 'class8': 0.9335378227654619, 'class9': 0.9607250658537254}\n",
            "Recall: {'class0': 0.9887755001145357, 'class1': 0.9814977887092706, 'class2': 0.9718992153885735, 'class3': 0.9772277130967554, 'class4': 0.9633401123896119, 'class5': 0.9708520070532286, 'class6': 0.9498956059509853, 'class7': 0.9620622474507564, 'class8': 0.9373716536204143, 'class9': 0.9454905753667932}\n",
            "F1 score: {'class0': 0.9867567007918824, 'class1': 0.9884599427043398, 'class2': 0.9785315760778958, 'class3': 0.934211754301066, 'class4': 0.9707492233003188, 'class5': 0.9665128464813416, 'class6': 0.9675654327237666, 'class7': 0.9681790338241192, 'class8': 0.9354458101353146, 'class9': 0.9530419438715937}\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96.50999999999999,\n",
              " {'class0': 0.9847560875532918,\n",
              "  'class1': 0.9955317158576255,\n",
              "  'class2': 0.9852652162547622,\n",
              "  'class3': 0.8948322674992542,\n",
              "  'class4': 0.9782833404520854,\n",
              "  'class5': 0.9622222115308643,\n",
              "  'class6': 0.9859154822761053,\n",
              "  'class7': 0.9743842268533573,\n",
              "  'class8': 0.9335378227654619,\n",
              "  'class9': 0.9607250658537254},\n",
              " {'class0': 0.9887755001145357,\n",
              "  'class1': 0.9814977887092706,\n",
              "  'class2': 0.9718992153885735,\n",
              "  'class3': 0.9772277130967554,\n",
              "  'class4': 0.9633401123896119,\n",
              "  'class5': 0.9708520070532286,\n",
              "  'class6': 0.9498956059509853,\n",
              "  'class7': 0.9620622474507564,\n",
              "  'class8': 0.9373716536204143,\n",
              "  'class9': 0.9454905753667932},\n",
              " {'class0': 0.9867567007918824,\n",
              "  'class1': 0.9884599427043398,\n",
              "  'class2': 0.9785315760778958,\n",
              "  'class3': 0.934211754301066,\n",
              "  'class4': 0.9707492233003188,\n",
              "  'class5': 0.9665128464813416,\n",
              "  'class6': 0.9675654327237666,\n",
              "  'class7': 0.9681790338241192,\n",
              "  'class8': 0.9354458101353146,\n",
              "  'class9': 0.9530419438715937})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkqT5Tk3tNX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "GRID_X_START = -1.5\n",
        "GRID_X_END = 2.5\n",
        "GRID_Y_START = -1.0\n",
        "GRID_Y_END = 2\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/nn_visuals/oop_adam\"\n",
        "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
        "grid_2d = grid.reshape(2,-1)\n",
        "XX, YY = grid\n",
        "def make_plot(X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False):\n",
        "    if (dark):\n",
        "        plt.style.use('dark_background')\n",
        "    else:\n",
        "        sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16,12))\n",
        "    axes = plt.gca()\n",
        "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
        "    plt.title(plot_name, fontsize=30)\n",
        "    plt.subplots_adjust(left=0.20)\n",
        "    plt.subplots_adjust(right=0.80)\n",
        "    if(XX is not None and YY is not None and preds is not None):\n",
        "        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha = 1, cmap=cm.Spectral)\n",
        "        plt.contour(XX, YY, preds.reshape(XX.shape), levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
        "    if(file_name):\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "import os\n",
        "def callback_numpy_plot(index, init_params):\n",
        "    plot_title = \"Iteration {:05}\".format(index)\n",
        "    file_name = \"numpy_model_{:05}.png\".format(index//1)\n",
        "    file_path = os.path.join(OUTPUT_DIR, file_name)\n",
        "    act = model.forward_prop(np.transpose(grid_2d))\n",
        "    prediction_probs = act[\"A6\"]\n",
        "    prediction_probs = prediction_probs.reshape(prediction_probs.shape[1], 1)\n",
        "    make_plot(X_cv, y_cv, plot_title, file_name=file_path, XX=XX, YY=YY, preds=prediction_probs, dark=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBa5oLGS0FPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.reset()\n",
        "model.add(\"dense1\",X_tr.shape[1],250,\"relu\")\n",
        "model.add(\"dense2\",250,150,\"relu\")\n",
        "model.add(\"dense3\",150,100,\"relu\")\n",
        "model.add(\"dense4\",100,60,\"relu\")\n",
        "model.add(\"dense5\",60,30,\"tanh\")\n",
        "model.add(\"dense6\",30,1,\"sigmoid\")\n",
        "model.fit(X_tr,y_tr,0.0005,50,\"Adam\",\"Binary\",mb=32,print_cost=False,callback=callback_numpy_plot)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSr56u3m2VfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act = model.forward_prop(np.transpose(grid_2d))\n",
        "prediction_probs_np = act[\"A6\"]\n",
        "prediction_probs_np = prediction_probs_np.reshape(prediction_probs_np.shape[1], 1)\n",
        "make_plot(X_cv, y_cv, \"Final Iteration\", file_name=None, XX=XX, YY=YY, preds=prediction_probs_np, dark=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG8sPwML4PDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}